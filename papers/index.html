<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Papers | GallantLab@UCBerkeley</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://gallantlab.org/papers/">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><meta name="author" content="Jack L. Gallant">
<meta property="og:site_name" content="GallantLab@UCBerkeley">
<meta property="og:title" content="Papers">
<meta property="og:url" content="https://gallantlab.org/papers/">
<meta property="og:description" content="Semantic representations during language production are affected by
context
(Deniz et al., J. Neuroscience, 2023).
Context is an important part of understanding the meaning of natural
language, but mo">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-03-24T23:52:52-07:00">
<meta property="article:tag" content="neuroscience">
<meta property="article:tag" content="publications">
<meta property="article:tag" content="research">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark
bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="../">

            <span id="blog-title">GallantLab@UCBerkeley</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../index.html" class="nav-link">Home</a>
                </li>
<li class="nav-item">
<a href="../brain_viewers/index.html" class="nav-link">BrainViewers</a>
                </li>
<li class="nav-item">
<a href="#" class="nav-link">Papers</a>
                </li>
<li class="nav-item">
<a href="../people/index.html" class="nav-link">People</a>
                </li>
<li class="nav-item">
<a href="../open_data/index.html" class="nav-link">OpenData</a>
                </li>
<li class="nav-item">
<a href="../open_code/index.html" class="nav-link">OpenCode</a>
                </li>
<li class="nav-item">
<a href="../blog/index.html" class="nav-link">Blog</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right">
<li class="nav-item">
    <a href="index.rst" id="sourcelink" class="nav-link">Source</a>
    </li>


                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Papers</a></h1>

        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <table><tbody>
<tr>
<td><img alt="/images/papers/Deniz.F.2023.png" src="../images/papers/Deniz.F.2023.png"></td>
<td><p><a class="reference external" href="https://www.biorxiv.org/content/10.1101/2021.12.15.472839.full.pdf">Semantic representations during language production are affected by
context
(Deniz et al., J. Neuroscience, 2023</a>).
Context is an important part of understanding the meaning of natural
language, but most neuroimaging studies of meaning use isolated words
and isolated sentences with little context. In this study we examined
whether the results of neuroimaging language studies that use
out-of-context stimuli generalize to natural language. We find that
increasing context improves the quality of neuroimaging data and
changes where and how semantic information is represented in the brain.
These results suggest that findings from studies using out-of-context
stimuli may not generalize to natural language used in daily life.</p></td>
</tr>
<tr>
<td><img alt="/images/papers/DuprelaTour.T.2022.png" src="../images/papers/DuprelaTour.T.2022.png"></td>
<td><p><a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811922008497">Feature-space selection with banded ridge regression
(Dupre la Tour et al., Neuroimage, 2022</a>).
Encoding models identify the information represented in brain
recordings, but fitting multiple models simultaneously presents
several challenges. This paper describes how banded ridge regression
can be used to solve these problems. Furthermore, several methods are
proposed to address the computational challenge of fitting banded
ridge regressions on large numbers of voxels and feature spaces. All
implementations are released in an open-source Python package called
Himalaya.</p></td>
</tr>
<tr>
<td><img alt="/images/papers/Popham.S.2021.png" src="../images/papers/Popham.S.2021.png"></td>
<td><p><a class="reference external" href="https://drive.google.com/file/d/1_CcPfViYAUQFD2HxdneEzSrmBwjd-QkJ/view">Visual and linguistic semantic representations are aligned at the
border of human visual cortex
(Popham et al., Nature Neuroscience, 2021</a>).
The human brain contains functionally and anatomically distinct networks
for representing semantic information in each sensory modality, and a
separate, distributed amodal conceptual network. In this study we
examined the spatial organization of visual and amodal semantic
functional maps. The pattern of semantic selectivity in these two
distinct networks corresponds along the boundary of visual cortex:
for visual categories represented posterior to the boundary, the
same categories are represented linguistically on the anterior side.
These results suggest that these two networks are smoothly joined
to form one contiguous map.</p></td>
</tr>
<tr>
<td><img alt="/images/papers/Zhang.T.2021.jpg" src="../images/papers/Zhang.T.2021.jpg"></td>
<td><p><a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fnins.2020.565976/full">Voxel-based state space modeling recovers task-related
cognitive states in naturalistic fMRI experiments
(Zhang et al., Front. Neuro., 2021</a>).
As of 2016
Complex natural tasks recruit many different functional brain networks,
and we understand little about how such tasks qre represented in the brain.
Here we present a voxel-based state space modeling method for recovering
task-related state spaces from human fMRI data. We apply this method to
data acquired in a controlled visual attention task and a video game task.
We show that each task induces distinct brain states that can be embedded
in a low-dimensional state space that reflects task parameters, and that
attention increases state separation in the task-related subspace.</p></td>
</tr>
<tr>
<td><img alt="/images/papers/Slivkoff.S.2021.png" src="../images/papers/Slivkoff.S.2021.png"></td>
<td><p><a class="reference external" href="https://www.cell.com/neuron/pdf/S0896-6273(21)00119-7.pdf">Design of complex neuroscience experiments
using mixed-integer linear programming
(Slivkoff and Gallant, Neuron, 2021</a>).
This tutorial and primer reviews how mixed integer linear
programming can be used to optimize the design of complex
experiments using many different variables. The approach is
particularly useful when designing complex fMRI experiments
--such as question answering studies--that aim to manipulat
and probe many dimensions simultaneously.</p></td>
</tr>
<tr>
<td><img alt="/images/papers/Deniz.F.2019.png" src="../images/papers/Deniz.F.2019.png"></td>
<td><p><a class="reference external" href="https://www.jneurosci.org/content/39/39/7722">The representation of semantic information across human cerebral cortex
during listening versus reading is invariant to stimulus modality
(Deniz et al., J. Neurosci., 2019</a>).
Humans can comprehend the meaning of words from both spoken and written
language. It is therefore important to understand the relationship between
the brain representations of spoken or written text. Here, we show that
although the representation of semantic information in the human brain is
quite complex, the semantic representations evoked by listening versus
reading are almost identical. These results suggest that the representation
of language semantics is independent of the sensory modality through which
the semantic information is received.</p></td>
</tr>
<tr>
<td><img alt="/images/papers/Lescroart.M.2019.jpg" src="../images/papers/Lescroart.M.2019.jpg"></td>
<td><p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4852309/">Human scene-selective areas represent 3D configurations of surfaces
(Lesroart et al., Neuron, 2019</a>).
It has been argued that scene-selective areas in the
human brain represent both the 3D structure of the
local visual environment and low-level 2D features
that provide cues for 3D structure. To evaluate these
hypotheses we developed an encoding model of 3D scene
structure and tested it against a model of low-
level 2D features. We fit the models to fMRI data
recorded while subjects viewed visual scenes. Scene-
selective areas represent the distance to and orientation
of large surfaces. The most important dimensions of 3D
structure are distance and openness.</p></td>
</tr>
<tr>
<td><img alt="/images/papers/Huth.A.2016.png" src="../images/papers/Huth.A.2016.png"></td>
<td><p><a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4852309/">Natural speech reveals the semantic maps that tile the
human cerebral cortex
(Huth et al., Nature, 2016</a>).
As of 2016 (when this paper appeared) little of the human
lexical-semantic system had been mapped comprehensively, and the
semantic selectivity of most regions was unknown. We collected
fMRI while subjects listened to narrative stories, and
recovered lexical-semantic maps by voxelwise modeling. We
showed that the semantic system is organized into intricate patterns
that seem to be consistent across individuals. We then used a generative
model to create a detailed semantic atlas. Our results show that most
areas within the semantic system represent information about groups
of related concepts, and the atlas shows which concepts are represented
in each area.</p></td>
</tr>
</tbody></table>
</div>
    

</article><!--End of body content--><footer id="footer">
            Site last updated on March 29, 2023 Â©          <a href="mailto:gallant@berkeley.edu">Jack L. Gallant</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
